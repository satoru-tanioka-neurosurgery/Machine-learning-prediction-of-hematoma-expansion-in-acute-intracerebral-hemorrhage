#上位9、CV

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix
from statistics import mean
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
from imblearn.over_sampling import RandomOverSampler

data=np.loadtxt('file_name_.csv',delimiter=',',skiprows=1,dtype=float)
y=data[:, 0:1].ravel()
x=data[:, 1:]

data_test=np.loadtxt('file_name.csv',delimiter=',',skiprows=1,dtype=float)
y_test=data_test[:, 0:1].ravel()
x_test=data_test[:, 1:]

sm=RandomOverSampler(random_state=4154)
x,y=sm.fit_sample(x,y)

model=KNeighborsClassifier(n_neighbors=5)

def splits(j):

    skf=StratifiedKFold(n_splits=j)

    x_train=[]
    x_val=[]
    y_train=[]
    y_val=[]

    for train,val in skf.split(x,y):
        x_train.append(x[train])
        x_val.append(x[val])
        y_train.append(y[train])
        y_val.append(y[val])

    mean_score_test=[]
    mean_sensitivity_test=[]
    mean_specificity_test=[]
    mean_auc_test=[]

    mean_score_val=[]
    mean_sensitivity_val=[]
    mean_specificity_val=[]
    mean_auc_val=[]

    for i in range(j):
        model.fit(x_train[i],y_train[i])
        score_val=model.score(x_val[i],y_val[i])
        print('score_val:{:.3f}'.format(score_val))
        predict_val=model.predict(x_val[i])
        confusion_val=confusion_matrix(y_val[i],predict_val)
        print("{}".format(confusion_val))
        tn,fp,fn,tp=confusion_matrix(y_val[i],predict_val).ravel()
        sensitivity_val=tp/(tp+fn)
        print("sensitivity_val:{:.3f}".format(sensitivity_val))
        specificity_val=tn/(tn+fp)
        print("specificity_val:{:.3f}".format(specificity_val))
        print()
        score_test=model.score(x_test,y_test)
        print('score_test:{:.3f}'.format(score_test))    
        predict_test=model.predict(x_test)
        confusion_test=confusion_matrix(y_test,predict_test)
        print("{}".format(confusion_test))
        tn,fp,fn,tp=confusion_matrix(y_test,predict_test).ravel()
        sensitivity_test=tp/(tp+fn)
        print("sensitivity_test:{:.3f}".format(sensitivity_test))
        specificity_test=tn/(tn+fp)
        print("specificity_test:{:.3f}".format(specificity_test))
        print()
        mean_score_test.append(score_test)
        mean_sensitivity_test.append(sensitivity_test)
        mean_specificity_test.append(specificity_test)
        fpr,tpr,thresholds=roc_curve(y_test,predict_test)
        auc_test=roc_auc_score(y_test,predict_test)
        mean_auc_test.append(auc_test)
        mean_score_val.append(score_val)
        mean_sensitivity_val.append(sensitivity_val)
        mean_specificity_val.append(specificity_val)
        auc_val=roc_auc_score(y_val[i],predict_val)
        mean_auc_val.append(auc_val)
        plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc_test)
        plt.legend()
        plt.title('ROC curve')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.grid(True)

    print('Average score_val: {:.3f}'.format(mean(mean_score_val))) 
    print('Average sensitivity_val: {:.3f}'.format(mean(mean_sensitivity_val))) 
    print('Average specificity_val: {:.3f}'.format(mean(mean_specificity_val))) 
    print('Average AUC_val: {:.3f}'.format(mean(mean_auc_val))) 
    print()
    print('Average score_test: {:.3f}'.format(mean(mean_score_test))) 
    print('Average sensitivity_test: {:.3f}'.format(mean(mean_sensitivity_test))) 
    print('Average specificity_test: {:.3f}'.format(mean(mean_specificity_test))) 
    print('Average AUC_test: {:.3f}'.format(mean(mean_auc_test))) 
    
splits(30)
